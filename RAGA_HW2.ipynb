{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hMczgJ9UDj",
        "outputId": "93735f56-c486-44c0-fbda-ab12bf2df86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.178.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.8.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.30)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: chromadb>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (1.0.17)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.14.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.25.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (2.20.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.25.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this first in your environment)\n",
        "!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
        "!pip install langchain-community langchain-chroma langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoFFzC_7DqEb",
        "outputId": "6a8aa91c-0ff4-4a6b-d432-921d60a7b2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Cell 3: Imports\n",
        "import glob\n",
        "from typing import List\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import hub\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8Sbsfp8PCr5n"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: Replace this with your actual OpenAI API key\n",
        "OPENAI_KEY = \"sk-proj-....\"  # Put your real key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sGOMZDtID0M7"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Simple RAG Class for Colab\n",
        "class ColabDriveRAG:\n",
        "    def __init__(self, openai_api_key: str):\n",
        "        self.openai_api_key = openai_api_key\n",
        "        self.vectorstore = None\n",
        "        self.retriever = None\n",
        "        self.rag_chain = None\n",
        "\n",
        "    def find_rag_folder(self):\n",
        "        \"\"\"Find the Rag folder in Google Drive\"\"\"\n",
        "        # Common paths where the folder might be\n",
        "        possible_paths = [\n",
        "            \"/content/drive/MyDrive/Rag\",\n",
        "            \"/content/drive/My Drive/Rag\",\n",
        "            \"/content/drive/MyDrive/rag\",\n",
        "            \"/content/drive/My Drive/rag\"\n",
        "        ]\n",
        "\n",
        "        print(\"Looking for Rag folder in Google Drive...\")\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                print(f\"✓ Found Rag folder at: {path}\")\n",
        "                return path\n",
        "\n",
        "        # If not found in common locations, search more broadly\n",
        "        print(\"Folder not found in common locations. Searching...\")\n",
        "\n",
        "        # Search in MyDrive root and one level deep\n",
        "        search_paths = [\n",
        "            \"/content/drive/MyDrive\",\n",
        "            \"/content/drive/My Drive\"\n",
        "        ]\n",
        "\n",
        "        for search_path in search_paths:\n",
        "            if os.path.exists(search_path):\n",
        "                # Check root level\n",
        "                for item in os.listdir(search_path):\n",
        "                    item_path = os.path.join(search_path, item)\n",
        "                    if os.path.isdir(item_path) and item.lower() == 'rag':\n",
        "                        print(f\"✓ Found Rag folder at: {item_path}\")\n",
        "                        return item_path\n",
        "\n",
        "                # Check one level deeper\n",
        "                for item in os.listdir(search_path):\n",
        "                    item_path = os.path.join(search_path, item)\n",
        "                    if os.path.isdir(item_path):\n",
        "                        try:\n",
        "                            for subitem in os.listdir(item_path):\n",
        "                                subitem_path = os.path.join(item_path, subitem)\n",
        "                                if os.path.isdir(subitem_path) and subitem.lower() == 'rag':\n",
        "                                    print(f\"✓ Found Rag folder at: {subitem_path}\")\n",
        "                                    return subitem_path\n",
        "                        except PermissionError:\n",
        "                            continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def list_all_folders(self):\n",
        "        \"\"\"List all folders in Google Drive to help user find their folder\"\"\"\n",
        "        print(\"\\n=== All folders in your Google Drive ===\")\n",
        "        search_paths = [\n",
        "            \"/content/drive/MyDrive\",\n",
        "            \"/content/drive/My Drive\"\n",
        "        ]\n",
        "\n",
        "        for search_path in search_paths:\n",
        "            if os.path.exists(search_path):\n",
        "                print(f\"\\nFolders in {search_path}:\")\n",
        "                try:\n",
        "                    for item in os.listdir(search_path):\n",
        "                        item_path = os.path.join(search_path, item)\n",
        "                        if os.path.isdir(item_path):\n",
        "                            print(f\"  📁 {item}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error reading directory: {e}\")\n",
        "\n",
        "    def load_documents_from_path(self, folder_path: str):\n",
        "        \"\"\"Load PDF documents from the specified folder path\"\"\"\n",
        "        if not os.path.exists(folder_path):\n",
        "            raise Exception(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "        # Find all PDF files in the folder\n",
        "        pdf_pattern = os.path.join(folder_path, \"*.pdf\")\n",
        "        pdf_files = glob.glob(pdf_pattern)\n",
        "\n",
        "        if not pdf_files:\n",
        "            raise Exception(f\"No PDF files found in folder: {folder_path}\")\n",
        "\n",
        "        print(f\"Found {len(pdf_files)} PDF files:\")\n",
        "        for pdf_file in pdf_files:\n",
        "            file_size = os.path.getsize(pdf_file) / (1024 * 1024)  # Convert to MB\n",
        "            print(f\"  - {os.path.basename(pdf_file)} ({file_size:.2f} MB)\")\n",
        "\n",
        "        # Load all PDF documents\n",
        "        documents = []\n",
        "        for pdf_file in pdf_files:\n",
        "            print(f\"\\nProcessing: {os.path.basename(pdf_file)}\")\n",
        "\n",
        "            try:\n",
        "                loader = PyPDFLoader(pdf_file, extract_images=True)\n",
        "                file_documents = loader.load()\n",
        "\n",
        "                # Add source information to metadata\n",
        "                for doc in file_documents:\n",
        "                    doc.metadata['source'] = os.path.basename(pdf_file)\n",
        "                    doc.metadata['file_path'] = pdf_file\n",
        "\n",
        "                documents.extend(file_documents)\n",
        "                print(f\"✓ Loaded {len(file_documents)} pages from {os.path.basename(pdf_file)}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Error loading {os.path.basename(pdf_file)}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\n✓ Total pages loaded: {len(documents)}\")\n",
        "        return documents\n",
        "\n",
        "    def create_vector_store(self, documents):\n",
        "        \"\"\"Create vector store from documents\"\"\"\n",
        "        if not documents:\n",
        "            raise Exception(\"No documents provided for vector store creation\")\n",
        "\n",
        "        # Split documents into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            add_start_index=True\n",
        "        )\n",
        "        all_splits = text_splitter.split_documents(documents)\n",
        "\n",
        "        print(f\"Total number of chunks after splitting: {len(all_splits)}\")\n",
        "\n",
        "        # Calculate chunk statistics\n",
        "        chunk_sizes = [len(chunk.page_content) for chunk in all_splits]\n",
        "        print(f\"Average chunk size: {sum(chunk_sizes) / len(chunk_sizes):.0f} characters\")\n",
        "        print(f\"Chunk size range: {min(chunk_sizes)} - {max(chunk_sizes)} characters\")\n",
        "\n",
        "        # Create vector store\n",
        "        print(\"Creating embeddings... (this may take a moment)\")\n",
        "        self.vectorstore = Chroma.from_documents(\n",
        "            documents=all_splits,\n",
        "            embedding=OpenAIEmbeddings(api_key=self.openai_api_key)\n",
        "        )\n",
        "\n",
        "        print(f\"✓ Vector store created with {self.vectorstore._collection.count()} embeddings\")\n",
        "\n",
        "        # Create retriever\n",
        "        self.retriever = self.vectorstore.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": 6}\n",
        "        )\n",
        "\n",
        "    def setup_rag_chain(self):\n",
        "        \"\"\"Setup the RAG chain for question answering\"\"\"\n",
        "        if not self.retriever:\n",
        "            raise Exception(\"Vector store not created. Call create_vector_store() first.\")\n",
        "\n",
        "        # Initialize LLM\n",
        "        llm = ChatOpenAI(\n",
        "            model=\"gpt-4\",\n",
        "            api_key=self.openai_api_key,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        # Get RAG prompt template\n",
        "        prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "        # Create RAG chain with sources\n",
        "        self.rag_chain = RunnableParallel(\n",
        "            {\"context\": self.retriever, \"question\": RunnablePassthrough()}\n",
        "        ).assign(\n",
        "            answer=prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        print(\"✓ RAG chain setup complete!\")\n",
        "\n",
        "    def query(self, question: str):\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        if not self.rag_chain:\n",
        "            raise Exception(\"RAG chain not set up. Call setup_rag_chain() first.\")\n",
        "\n",
        "        result = self.rag_chain.invoke(question)\n",
        "\n",
        "        # Format sources for display\n",
        "        sources = []\n",
        "        for i, doc in enumerate(result['context']):\n",
        "            source_name = doc.metadata.get('source', 'Unknown')\n",
        "            page = doc.metadata.get('page', 'Unknown')\n",
        "            sources.append({\n",
        "                'index': i + 1,\n",
        "                'source': source_name,\n",
        "                'page': page,\n",
        "                'content_preview': doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            'answer': result['answer'],\n",
        "            'sources': sources\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zIM_TVc4D5dX",
        "outputId": "5f4cde9b-7cd1-4dc6-fb2b-88282685b7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ OpenAI API key detected (length: 164)\n",
            "Looking for Rag folder in Google Drive...\n",
            "Folder not found in common locations. Searching...\n",
            "✓ Found Rag folder at: /content/drive/MyDrive/RAG\n",
            "\n",
            "📁 Loading documents from Google Drive...\n",
            "Found 2 PDF files:\n",
            "  - Zhuowan_et_al.pdf (0.62 MB)\n",
            "  - Wang_et_al.pdf (0.87 MB)\n",
            "\n",
            "Processing: Zhuowan_et_al.pdf\n",
            "✓ Loaded 12 pages from Zhuowan_et_al.pdf\n",
            "\n",
            "Processing: Wang_et_al.pdf\n",
            "✓ Loaded 22 pages from Wang_et_al.pdf\n",
            "\n",
            "✓ Total pages loaded: 34\n",
            "\n",
            "🔍 Creating vector store...\n",
            "Total number of chunks after splitting: 165\n",
            "Average chunk size: 879 characters\n",
            "Chunk size range: 206 - 999 characters\n",
            "Creating embeddings... (this may take a moment)\n",
            "✓ Vector store created with 495 embeddings\n",
            "\n",
            "⚙️ Setting up RAG chain...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ RAG chain setup complete!\n",
            "\n",
            "================================================================================\n",
            "🚀 TESTING RAG SYSTEM\n",
            "================================================================================\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 1: What is the primary goal of the SELF-ROUTE method proposed by Zhuowan Li?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=112d7250-aa9c-4d98-beb0-e0c75c71daca; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=e56e641b-ce28-4fa7-a9b9-28b30968e071; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=01b0539e-63e9-411a-b464-5d447b0d8616; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=31ddf108-946e-40b5-b49c-b71ed4f5cff0; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=31ddf108-946e-40b5-b49c-b71ed4f5cff0\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=01b0539e-63e9-411a-b464-5d447b0d8616; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=e56e641b-ce28-4fa7-a9b9-28b30968e071; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=dc70d91a-b087-4e92-9812-794914665db1; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=bb1b09f4-bbed-4202-b9fa-efa4162937c4; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=01c8eb8e-2607-400f-88a6-61bcbd37eb61; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=de8eaca4-0c8e-4c8d-85e5-9af8ce0012c9; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=de8eaca4-0c8e-4c8d-85e5-9af8ce0012c9; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=b69ffa31-82f8-4de4-9a94-5228e3529325\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The primary goal of the SELF-ROUTE method proposed by Zhuowan Li is to combine RAG (Retrieval-Augmented Generation) and LC (Long-Context) to reduce computational costs while maintaining a performance comparable to LC. The method utilizes LLM (Language Model) to route queries based on self-reflection, under the assumption that LLMs are well-calibrated in predicting whether a query is answerable given the provided context. The method consists of two steps: a RAG-and-Route step and a long-context prediction step.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 3\n",
            "  [2] Zhuowan_et_al.pdf, Page 3\n",
            "  [3] Zhuowan_et_al.pdf, Page 3\n",
            "  [4] Zhuowan_et_al.pdf, Page 4\n",
            "  [5] Zhuowan_et_al.pdf, Page 4\n",
            "  [6] Zhuowan_et_al.pdf, Page 4\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 2: Explain why the researchers believe RAG might still be useful despite the superior performance of long-context LLMs\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=b69ffa31-82f8-4de4-9a94-5228e3529325; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=1c313518-04b2-49dd-a401-5d1b55ace26d; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=1c313518-04b2-49dd-a401-5d1b55ace26d; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=01c8eb8e-2607-400f-88a6-61bcbd37eb61; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=bb1b09f4-bbed-4202-b9fa-efa4162937c4; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=dc70d91a-b087-4e92-9812-794914665db1; trace=112d7250-aa9c-4d98-beb0-e0c75c71daca,id=112d7250-aa9c-4d98-beb0-e0c75c71daca; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=6287c7e8-1463-44b8-92fb-0830e73eab09; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=cc4158ea-c55c-4c2b-b1da-358ae3971866; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=523590ee-1d93-42e3-bb1c-37f2c2bc9a8c; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=352660b1-c088-4355-a9c1-832af734b9db; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=352660b1-c088-4355-a9c1-832af734b9db; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=523590ee-1d93-42e3-bb1c-37f2c2bc9a8c; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=cc4158ea-c55c-4c2b-b1da-358ae3971866; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=c5039a46-7a99-4ad1-a196-1146c419521a; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=fc48cce4-b97e-4a18-90c3-78cf4d4feef2; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=e57a5bb1-660b-42b0-add3-e22d3eaeaff7; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=39144c1c-3f2c-4d4d-9482-55968e02166f; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=39144c1c-3f2c-4d4d-9482-55968e02166f; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=261cc303-04f1-46ef-afcf-d769e0e43ac6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The researchers believe RAG might still be useful despite the superior performance of long-context LLMs because RAG has a significantly lower computational cost. RAG decreases the input length to LLMs, which leads to reduced costs, especially considering that LLM API pricing is typically based on the amount of information processed. Furthermore, RAG can help avoid the distraction of irrelevant information and save unnecessary attention computations.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 0\n",
            "  [2] Zhuowan_et_al.pdf, Page 0\n",
            "  [3] Zhuowan_et_al.pdf, Page 0\n",
            "  [4] Zhuowan_et_al.pdf, Page 0\n",
            "  [5] Zhuowan_et_al.pdf, Page 0\n",
            "  [6] Zhuowan_et_al.pdf, Page 0\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 3: Compare the reranking techniques mentioned in the Wang paper. How do they impact the retrieval quality?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=261cc303-04f1-46ef-afcf-d769e0e43ac6; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=c87bc8e8-2238-4cc9-bba3-1da245aedabb; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=c87bc8e8-2238-4cc9-bba3-1da245aedabb; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=e57a5bb1-660b-42b0-add3-e22d3eaeaff7; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=fc48cce4-b97e-4a18-90c3-78cf4d4feef2; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=c5039a46-7a99-4ad1-a196-1146c419521a; trace=6287c7e8-1463-44b8-92fb-0830e73eab09,id=6287c7e8-1463-44b8-92fb-0830e73eab09; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=60f5ab37-05fa-45cb-8bbb-4b75192d8908; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=cfd3c713-79de-4eb2-b311-66c296269dcc; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=b0d7bfa4-b1ba-4645-940f-827eed6e2801; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=b98f720e-d86e-4484-b96d-d9f8970ea25f; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=b98f720e-d86e-4484-b96d-d9f8970ea25f\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=b0d7bfa4-b1ba-4645-940f-827eed6e2801; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=cfd3c713-79de-4eb2-b311-66c296269dcc; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=ab4f490b-dffd-4905-a77b-1f486a27ce42; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=37a65d2a-549c-433d-98ad-95b0d42c092b; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=be05fb49-8236-47eb-876c-a914524ec24e; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=a1c013d7-da44-465b-a2c8-7c9f5d60677d; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=a1c013d7-da44-465b-a2c8-7c9f5d60677d; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=387db807-9d40-4f7d-97f5-31ac8c74e77b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The Wang paper discusses two reranking techniques: DLM Reranking and TILDE Reranking. DLM Reranking uses deep language models to classify document relevancy to a query as \"true\" or \"false\", and documents are ranked based on the probability of the \"true\" token. This method can be time-intensive but offers better performance. On the other hand, TILDE Reranking focuses on query likelihoods, achieving efficiency by precomputing and storing the likelihood of query terms and ranking documents based on their sum. These techniques enhance the relevance of retrieved documents, ensuring the most pertinent information appears at the top.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Wang_et_al.pdf, Page 7\n",
            "  [2] Wang_et_al.pdf, Page 7\n",
            "  [3] Wang_et_al.pdf, Page 7\n",
            "  [4] Wang_et_al.pdf, Page 2\n",
            "  [5] Wang_et_al.pdf, Page 2\n",
            "  [6] Wang_et_al.pdf, Page 2\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 4: What are the trade-offs involved when using different chunking strategies in RAG systems?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=387db807-9d40-4f7d-97f5-31ac8c74e77b; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=1afa773e-4b3d-447e-a641-86d28518e704; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=1afa773e-4b3d-447e-a641-86d28518e704; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=be05fb49-8236-47eb-876c-a914524ec24e; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=37a65d2a-549c-433d-98ad-95b0d42c092b; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=ab4f490b-dffd-4905-a77b-1f486a27ce42; trace=60f5ab37-05fa-45cb-8bbb-4b75192d8908,id=60f5ab37-05fa-45cb-8bbb-4b75192d8908; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=9dc2338e-bb30-4930-82f2-5e107d87d451; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=5eee803f-bdec-4d35-a8e0-50c7d72284e1; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=3ac434b2-1ed3-439f-ba5f-438ec7e96a84; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=3ac434b2-1ed3-439f-ba5f-438ec7e96a84; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=5eee803f-bdec-4d35-a8e0-50c7d72284e1; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=9dc2338e-bb30-4930-82f2-5e107d87d451; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=9cef4ee9-54cb-4aad-94e5-5610d3c6d4a5; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=e8bdcef9-80c3-42a0-bf81-5364ad86c93c; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=4701a41c-58f8-4192-915a-b97edecae8b8; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=47c09f9c-4c05-4b8a-a85c-f8bdc57bff47; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=47c09f9c-4c05-4b8a-a85c-f8bdc57bff47; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=d573b9d0-2417-420d-9d2d-14ef530fca5b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The trade-offs involved when using different chunking strategies in RAG systems can include balancing performance and efficiency. Different strategies may be more suitable for different application scenarios, where efficiency might be prioritized over performance, or vice versa. However, the specific trade-offs can depend on the effectiveness and influence of the chunking techniques used within the chunking module.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Wang_et_al.pdf, Page 13\n",
            "  [2] Wang_et_al.pdf, Page 13\n",
            "  [3] Wang_et_al.pdf, Page 13\n",
            "  [4] Wang_et_al.pdf, Page 1\n",
            "  [5] Wang_et_al.pdf, Page 1\n",
            "  [6] Wang_et_al.pdf, Page 1\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 5: How does multimodal retrieval enhance the capabilities of RAG?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=d573b9d0-2417-420d-9d2d-14ef530fca5b; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=558fa035-d5ec-4bd1-b96d-18a220e3bf83; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=558fa035-d5ec-4bd1-b96d-18a220e3bf83; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=4701a41c-58f8-4192-915a-b97edecae8b8; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=e8bdcef9-80c3-42a0-bf81-5364ad86c93c; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=9cef4ee9-54cb-4aad-94e5-5610d3c6d4a5; trace=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9,id=d0d72beb-d276-4b9a-8cc6-790fc3e1ebf9; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=ae3860a5-30da-48a9-bd4a-c36687ddf897; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=0cc7603c-d8ce-4968-b4ca-e89f9967722d; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=1580e3f9-1d17-42ba-a3d9-07924f69d065; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=9044fd19-43a3-4138-b647-a9a3a5484817; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=9044fd19-43a3-4138-b647-a9a3a5484817; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=1580e3f9-1d17-42ba-a3d9-07924f69d065; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=0cc7603c-d8ce-4968-b4ca-e89f9967722d; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=aa2abbbd-00e9-40e1-ba66-356607f5af37; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=6bf98e09-f914-44ea-a127-36642a95841b; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=458b4f6f-4aeb-4e90-be32-fb199568e744; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=bf1a1cd7-484d-45d5-a1ec-73996e9e19f2; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=bf1a1cd7-484d-45d5-a1ec-73996e9e19f2; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=f09cfef6-2560-40a4-ba69-4b076c2e9ced\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The integration of multimodal retrieval techniques enhances the capabilities of Retrieval-Augmented Generation (RAG) by substantially improving question-answering capabilities on visual inputs. It also speeds up the generation of multimodal content through a strategy of \"retrieval as generation\". This approach enhances both the performance and efficiency of RAG.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Wang_et_al.pdf, Page 2\n",
            "  [2] Wang_et_al.pdf, Page 2\n",
            "  [3] Wang_et_al.pdf, Page 2\n",
            "  [4] Wang_et_al.pdf, Page 0\n",
            "  [5] Wang_et_al.pdf, Page 0\n",
            "  [6] Wang_et_al.pdf, Page 0\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 6: What were the key failure cases for RAG in handling long context retrievals, as noted by Zhuowan Li?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=f09cfef6-2560-40a4-ba69-4b076c2e9ced; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=f81ce1ab-9783-4b2f-944d-e0d4b54dbbfa; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=f81ce1ab-9783-4b2f-944d-e0d4b54dbbfa; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=458b4f6f-4aeb-4e90-be32-fb199568e744; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=6bf98e09-f914-44ea-a127-36642a95841b; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=aa2abbbd-00e9-40e1-ba66-356607f5af37; trace=ae3860a5-30da-48a9-bd4a-c36687ddf897,id=ae3860a5-30da-48a9-bd4a-c36687ddf897; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=02778bf7-24b0-43c1-8cd3-d7b2eab62614; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=5446fc63-4918-475f-bdc9-8cf1291e4ebf; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=b64355bd-0d8d-4f9c-ad66-47eb9e7d391f; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=86336e2b-3bd3-4011-8953-e1f59e2dfd18; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=86336e2b-3bd3-4011-8953-e1f59e2dfd18\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=b64355bd-0d8d-4f9c-ad66-47eb9e7d391f; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=5446fc63-4918-475f-bdc9-8cf1291e4ebf; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=d930e726-e380-4d15-8723-e3a63efc8e25; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=d8bd7ec7-9a6b-460a-baf9-26c68de52dcf; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=6fce18ef-1057-4177-ae75-baad42081ec2; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=9d11aa6e-d0a3-471f-b6a9-aa41c2c660f5; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=9d11aa6e-d0a3-471f-b6a9-aa41c2c660f5; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=2d2197f4-5d33-4a3b-a9e0-4718091516c7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The provided context does not specify the key failure cases for RAG in handling long context retrievals as noted by Zhuowan Li.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 1\n",
            "  [2] Zhuowan_et_al.pdf, Page 1\n",
            "  [3] Zhuowan_et_al.pdf, Page 1\n",
            "  [4] Zhuowan_et_al.pdf, Page 1\n",
            "  [5] Zhuowan_et_al.pdf, Page 1\n",
            "  [6] Zhuowan_et_al.pdf, Page 1\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 7: Why does the Zhuowan paper claim that long-context LLMs outperformed RAG in most cases? What benefits does RAG still offer?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=2d2197f4-5d33-4a3b-a9e0-4718091516c7; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=e39d1fc0-2761-4a57-bd07-c929fa65fdc5; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=e39d1fc0-2761-4a57-bd07-c929fa65fdc5; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=6fce18ef-1057-4177-ae75-baad42081ec2; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=d8bd7ec7-9a6b-460a-baf9-26c68de52dcf; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=d930e726-e380-4d15-8723-e3a63efc8e25; trace=02778bf7-24b0-43c1-8cd3-d7b2eab62614,id=02778bf7-24b0-43c1-8cd3-d7b2eab62614; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=f4364380-0540-4acf-9a6b-f5e393b00de9; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=74b739d4-a4a3-4272-b609-437cc72aa474; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=311d1f89-4f0c-4e63-b33b-97fc9da80217; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=84873c3d-39db-47da-875e-4e666453c235; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=84873c3d-39db-47da-875e-4e666453c235; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=311d1f89-4f0c-4e63-b33b-97fc9da80217; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=74b739d4-a4a3-4272-b609-437cc72aa474; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=75365a52-321a-4f84-9070-b85ac09c507d; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=73e07998-1fc8-49e9-917f-4b27c50a16d8; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=4091b119-45ef-4c82-ae85-91774b1dee3f; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=02b4f606-443f-4d3f-9e59-07394789c425; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=02b4f606-443f-4d3f-9e59-07394789c425; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=12445ef1-45ac-4a03-9902-8cdc51112dd6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The Zhuowan paper claims that long-context LLMs outperformed RAG in most cases because recent advancements in LLMs have led to stronger long-context understanding capabilities. When sufficiently resourced, LC consistently outperforms RAG in almost all settings. However, RAG still offers the benefit of significantly lower computational cost, as it decreases the input length to LLMs, leading to reduced costs.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 0\n",
            "  [2] Zhuowan_et_al.pdf, Page 0\n",
            "  [3] Zhuowan_et_al.pdf, Page 0\n",
            "  [4] Zhuowan_et_al.pdf, Page 0\n",
            "  [5] Zhuowan_et_al.pdf, Page 0\n",
            "  [6] Zhuowan_et_al.pdf, Page 0\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 8: Describe the metrics used to evaluate the different embedding models for RAG in Wang's paper\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=12445ef1-45ac-4a03-9902-8cdc51112dd6; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=1b3af386-7ea6-4ff4-bc21-b1145b1d7e56; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=1b3af386-7ea6-4ff4-bc21-b1145b1d7e56; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=4091b119-45ef-4c82-ae85-91774b1dee3f; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=73e07998-1fc8-49e9-917f-4b27c50a16d8; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=75365a52-321a-4f84-9070-b85ac09c507d; trace=f4364380-0540-4acf-9a6b-f5e393b00de9,id=f4364380-0540-4acf-9a6b-f5e393b00de9; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=8623c0d8-9951-41f0-8c73-e40f5c0e87ac; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=b0d337cf-8a94-4faf-b668-cb256b65404f; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=f06b86dc-fd02-4ecd-a016-f1d365f4a320; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=f06b86dc-fd02-4ecd-a016-f1d365f4a320; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=b0d337cf-8a94-4faf-b668-cb256b65404f; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=8623c0d8-9951-41f0-8c73-e40f5c0e87ac; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=5f745858-f0ca-42d9-a114-a5c25d9581d7; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=7d039e5a-f56f-4688-9285-b39a300733ae; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=f05c6e08-9506-44e2-84d2-69a9bd2521d0; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=01e80c05-7051-4659-bc6e-70da9a39cc1c; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=01e80c05-7051-4659-bc6e-70da9a39cc1c; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=02e5426d-f173-4cd0-ba1e-dd8539bf6aa0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The provided context does not contain information about the specific metrics used to evaluate the different embedding models for RAG in Wang's paper.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 1\n",
            "  [2] Zhuowan_et_al.pdf, Page 1\n",
            "  [3] Zhuowan_et_al.pdf, Page 1\n",
            "  [4] Wang_et_al.pdf, Page 13\n",
            "  [5] Wang_et_al.pdf, Page 13\n",
            "  [6] Wang_et_al.pdf, Page 13\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 9: Discuss the implications of using self-reflection in routing queries between RAG and long-context LLMs\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=02e5426d-f173-4cd0-ba1e-dd8539bf6aa0; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=a8227e01-b741-4223-8e80-d1cb934b12f9; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=a8227e01-b741-4223-8e80-d1cb934b12f9; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=f05c6e08-9506-44e2-84d2-69a9bd2521d0; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=7d039e5a-f56f-4688-9285-b39a300733ae; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=5f745858-f0ca-42d9-a114-a5c25d9581d7; trace=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928,id=9f2e6d5b-0c33-4059-b8f6-67e40bcd3928; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=00891813-fd29-453c-a457-00d1d281124e; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=b17e9331-432b-4b15-a306-8da2cc69abeb; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=abf385b9-25a0-4219-a324-5b3c0e0637dc; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=abf385b9-25a0-4219-a324-5b3c0e0637dc; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=b17e9331-432b-4b15-a306-8da2cc69abeb; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=00891813-fd29-453c-a457-00d1d281124e; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=95a8be03-9b43-4e9e-8cbf-4e973e5c44ea; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=dbdc4b94-00da-45d6-ae20-76589e0af2e4; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=1004cdc0-d1f5-4489-b53b-ea53109526fd; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=c96424a8-cfee-4f85-be54-147fcbebcba8; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=c96424a8-cfee-4f85-be54-147fcbebcba8; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=bd3b8f63-fd2d-4e44-ab76-c841f0768fdd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: Using self-reflection in routing queries between RAG and long-context LLMs effectively combines the strengths of both, achieving performance comparable to LC but at a significantly reduced cost. This approach leverages RAG for most queries, reserving the more computationally expensive LC for a subset of queries where it excels. This method, called SELF-ROUTE, uses the LLM itself to route queries based on self-reflection, under the assumption that LLMs are well-calibrated in predicting whether a query is answerable given the provided context.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 5\n",
            "  [2] Zhuowan_et_al.pdf, Page 5\n",
            "  [3] Zhuowan_et_al.pdf, Page 5\n",
            "  [4] Zhuowan_et_al.pdf, Page 3\n",
            "  [5] Zhuowan_et_al.pdf, Page 3\n",
            "  [6] Zhuowan_et_al.pdf, Page 3\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 10: How does query rewriting contribute to the overall efficiency of RAG according to Wang's findings?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=bd3b8f63-fd2d-4e44-ab76-c841f0768fdd; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=5cd7c224-95e8-4f37-ab15-58c78b47c91d; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=5cd7c224-95e8-4f37-ab15-58c78b47c91d; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=1004cdc0-d1f5-4489-b53b-ea53109526fd; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=dbdc4b94-00da-45d6-ae20-76589e0af2e4; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=95a8be03-9b43-4e9e-8cbf-4e973e5c44ea; trace=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc,id=c34db5a5-9220-4a2f-a123-c5d5b4ebdbdc; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=7f65037f-5e39-4bc5-a502-97830a227266; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=81157fda-d357-4da0-896d-3c6f18874aa1; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=8b257a17-d003-40f9-a9a8-2a3e1201f837; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=2909684b-81e6-49c0-9067-1bc27fbfbd79; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=2909684b-81e6-49c0-9067-1bc27fbfbd79; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=8b257a17-d003-40f9-a9a8-2a3e1201f837; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=81157fda-d357-4da0-896d-3c6f18874aa1; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=e8785990-7048-4ac2-b610-345de32e3bc5; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=fd33071a-4606-446c-8909-e567fcd206de; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=62a2c447-e287-415f-afb2-a2f0619d9a2d; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=c6380b12-b303-42d1-955e-ec1900a07eb8; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=c6380b12-b303-42d1-955e-ec1900a07eb8; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=eb93c13e-cf28-4e0e-bb89-df315deedf00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: According to Wang's findings, query rewriting contributes to the overall efficiency of RAG by being used as a method for retrieving relevant documents for an input query. The rewritten queries are used for retrieval, which significantly impacts both the effectiveness and efficiency of RAG systems. This approach is one of the various methods that can be employed in the RAG workflow.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 5\n",
            "  [2] Zhuowan_et_al.pdf, Page 5\n",
            "  [3] Zhuowan_et_al.pdf, Page 5\n",
            "  [4] Wang_et_al.pdf, Page 1\n",
            "  [5] Wang_et_al.pdf, Page 1\n",
            "  [6] Wang_et_al.pdf, Page 1\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 11: Compare the cost-efficiency and performance trade-offs between RAG and long-context language models (LC) as discussed in the Wang and Zhuowan Li papers. How do these methods balance the ability to handle large volumes of text with computational demands?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=7f65037f-5e39-4bc5-a502-97830a227266,id=eb93c13e-cf28-4e0e-bb89-df315deedf00; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=73e36642-2512-43e4-8799-89fd9a76e145; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=73e36642-2512-43e4-8799-89fd9a76e145; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=62a2c447-e287-415f-afb2-a2f0619d9a2d; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=fd33071a-4606-446c-8909-e567fcd206de; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=e8785990-7048-4ac2-b610-345de32e3bc5; trace=7f65037f-5e39-4bc5-a502-97830a227266,id=7f65037f-5e39-4bc5-a502-97830a227266; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=be21a773-d8c5-48a2-a1e0-cf5b86f59a33; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=e195afb2-6696-4aed-89d4-13504827b3dc; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=1202cda6-e098-4f84-b0a3-ce3eb593ca7c; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=1cb945e3-70cc-4010-bd8e-38664f3afba1; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=1cb945e3-70cc-4010-bd8e-38664f3afba1; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=1202cda6-e098-4f84-b0a3-ce3eb593ca7c; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=e195afb2-6696-4aed-89d4-13504827b3dc; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=69e25e74-6c5e-4088-ac69-0e329e18c094; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=ada0889b-1f03-4205-a70e-890eccc508ea; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=b831a98a-e3ae-44f3-b9d6-db809ad35ac7; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=bd6ebb74-89d2-49d9-be71-dbb7bc5f8395; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=bd6ebb74-89d2-49d9-be71-dbb7bc5f8395; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=8a579cda-1ab2-46c7-bc17-a4027fa6fc90\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The Wang and Zhuowan Li papers found that long-context language models (LC) consistently outperform RAG in almost all settings when sufficiently resourced, indicating superior progress in long-context understanding. However, despite its suboptimal performance, RAG remains relevant due to its significantly lower computational cost. RAG significantly decreases the input length to LLMs, leading to reduced costs, which is beneficial when handling large volumes of text.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Zhuowan_et_al.pdf, Page 0\n",
            "  [2] Zhuowan_et_al.pdf, Page 0\n",
            "  [3] Zhuowan_et_al.pdf, Page 0\n",
            "  [4] Zhuowan_et_al.pdf, Page 1\n",
            "  [5] Zhuowan_et_al.pdf, Page 1\n",
            "  [6] Zhuowan_et_al.pdf, Page 1\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 12: In terms of chunking methods in Wang's paper, what is the difference in performance between the best and second-best methods in Table 4?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=8a579cda-1ab2-46c7-bc17-a4027fa6fc90; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=677feea2-e885-4f29-a82e-289f10d71ab6; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=677feea2-e885-4f29-a82e-289f10d71ab6; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=b831a98a-e3ae-44f3-b9d6-db809ad35ac7; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=ada0889b-1f03-4205-a70e-890eccc508ea; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=69e25e74-6c5e-4088-ac69-0e329e18c094; trace=be21a773-d8c5-48a2-a1e0-cf5b86f59a33,id=be21a773-d8c5-48a2-a1e0-cf5b86f59a33; trace=479ada13-d53b-4abe-86b1-924458731686,id=479ada13-d53b-4abe-86b1-924458731686; trace=479ada13-d53b-4abe-86b1-924458731686,id=78a2860c-7301-4e1d-a8e8-3f196c89ef06; trace=479ada13-d53b-4abe-86b1-924458731686,id=a17b339c-fa02-4f3c-82bd-14ff5fc5cab7; trace=479ada13-d53b-4abe-86b1-924458731686,id=9e23496b-7f44-4087-805c-69c088b4178d; trace=479ada13-d53b-4abe-86b1-924458731686,id=9e23496b-7f44-4087-805c-69c088b4178d; trace=479ada13-d53b-4abe-86b1-924458731686,id=a17b339c-fa02-4f3c-82bd-14ff5fc5cab7; trace=479ada13-d53b-4abe-86b1-924458731686,id=78a2860c-7301-4e1d-a8e8-3f196c89ef06; trace=479ada13-d53b-4abe-86b1-924458731686,id=b933f858-556f-4088-b6a4-c104519e615b; trace=479ada13-d53b-4abe-86b1-924458731686,id=ae928bf9-aa21-4d9b-a8c4-5a364e3b66b9; trace=479ada13-d53b-4abe-86b1-924458731686,id=7d696dfe-3d17-43ea-b205-72b88e03e796; trace=479ada13-d53b-4abe-86b1-924458731686,id=f885c436-3933-4c89-89e9-03e6fe1bd292; trace=479ada13-d53b-4abe-86b1-924458731686,id=f885c436-3933-4c89-89e9-03e6fe1bd292; trace=479ada13-d53b-4abe-86b1-924458731686,id=cc9db3b6-8ffa-41c4-a199-b8c6b70f6bbe\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The provided context does not include specific information about the performance difference between the best and second-best chunking methods in Table 4 of Wang's paper.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Wang_et_al.pdf, Page 5\n",
            "  [2] Wang_et_al.pdf, Page 5\n",
            "  [3] Wang_et_al.pdf, Page 4\n",
            "  [4] Wang_et_al.pdf, Page 4\n",
            "  [5] Wang_et_al.pdf, Page 4\n",
            "  [6] Wang_et_al.pdf, Page 4\n",
            "\n",
            "------------------------------------------------------------\n",
            "📝 QUERY 13: What are the best approaches for the retrieval and reranking modules according to Table 11 in Wang paper?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=479ada13-d53b-4abe-86b1-924458731686,id=cc9db3b6-8ffa-41c4-a199-b8c6b70f6bbe; trace=479ada13-d53b-4abe-86b1-924458731686,id=bd496a5a-e706-42ee-b2a8-8ef17ebec979; trace=479ada13-d53b-4abe-86b1-924458731686,id=bd496a5a-e706-42ee-b2a8-8ef17ebec979; trace=479ada13-d53b-4abe-86b1-924458731686,id=7d696dfe-3d17-43ea-b205-72b88e03e796; trace=479ada13-d53b-4abe-86b1-924458731686,id=ae928bf9-aa21-4d9b-a8c4-5a364e3b66b9; trace=479ada13-d53b-4abe-86b1-924458731686,id=b933f858-556f-4088-b6a4-c104519e615b; trace=479ada13-d53b-4abe-86b1-924458731686,id=479ada13-d53b-4abe-86b1-924458731686; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=55b0e928-14e0-40ae-ba07-376fa8a3350f; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=27b35207-a734-45d6-9356-1ce02c76099f; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=4f4954f7-db30-42d1-b1b6-63e0df796989; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=075866c2-d08b-4259-8ab2-62a041e8c358; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=075866c2-d08b-4259-8ab2-62a041e8c358\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=4f4954f7-db30-42d1-b1b6-63e0df796989; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=27b35207-a734-45d6-9356-1ce02c76099f; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=29908df3-c021-4321-8693-bb734c5bfdfd; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=3eb8ab23-1ef6-4176-9c7d-3b5f7e8dff33; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=aeff4128-6a2e-4d58-bf23-c3ee3b9ed84b; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=9d290429-09e1-48e4-9be0-371acc28a06c; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=9d290429-09e1-48e4-9be0-371acc28a06c; trace=55b0e928-14e0-40ae-ba07-376fa8a3350f,id=54c4197e-d78d-4102-a57c-9300f5d14563\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💡 ANSWER: The context does not provide information on the best approaches for the retrieval and reranking modules according to Table 11 in the Wang paper.\n",
            "\n",
            "📚 SOURCES:\n",
            "  [1] Wang_et_al.pdf, Page 7\n",
            "  [2] Wang_et_al.pdf, Page 7\n",
            "  [3] Wang_et_al.pdf, Page 7\n",
            "  [4] Wang_et_al.pdf, Page 2\n",
            "  [5] Wang_et_al.pdf, Page 2\n",
            "  [6] Wang_et_al.pdf, Page 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Manual setup if automatic detection fails\\nrag_system = ColabDriveRAG(OPENAI_KEY)\\n\\n# Replace this path with your actual folder path\\nmanual_folder_path = \"/content/drive/MyDrive/Rag\"\\n\\ntry:\\n    documents = rag_system.load_documents_from_path(manual_folder_path)\\n    rag_system.create_vector_store(documents)\\n    rag_system.setup_rag_chain()\\n    \\n    # Test a single query\\n    result = rag_system.query(\"What is the main topic of these documents?\")\\n    print(f\"Answer: {result[\\'answer\\']}\")\\n    \\nexcept Exception as e:\\n    print(f\"Error: {e}\")\\n'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 6: Main function\n",
        "def main():\n",
        "    # Validate OpenAI API key\n",
        "    if not OPENAI_KEY or len(OPENAI_KEY) < 20 or not OPENAI_KEY.startswith('sk-'):\n",
        "        print(\"❌ ERROR: Please set your OpenAI API key!\")\n",
        "        print(\"Edit the OPENAI_KEY variable with your actual key.\")\n",
        "        print(\"Your key should start with 'sk-' and be about 50+ characters long.\")\n",
        "        print(f\"Current key length: {len(OPENAI_KEY) if OPENAI_KEY else 0}\")\n",
        "        return\n",
        "\n",
        "    print(f\"✅ OpenAI API key detected (length: {len(OPENAI_KEY)})\")\n",
        "\n",
        "    # Initialize RAG system\n",
        "    rag_system = ColabDriveRAG(OPENAI_KEY)\n",
        "\n",
        "    # Try to find the Rag folder automatically\n",
        "    rag_folder_path = rag_system.find_rag_folder()\n",
        "\n",
        "    if not rag_folder_path:\n",
        "        print(\"❌ Could not find 'Rag' folder automatically.\")\n",
        "        print(\"\\nLet me show you all the folders in your Google Drive:\")\n",
        "        rag_system.list_all_folders()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MANUAL SETUP REQUIRED\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Please check the folder list above and:\")\n",
        "        print(\"1. Make sure you have a folder named 'Rag' (or 'rag') in your Google Drive\")\n",
        "        print(\"2. Put your PDF files in that folder\")\n",
        "        print(\"3. Or modify the code below to use the correct path\")\n",
        "        print(\"\\nExample: If your folder is at '/content/drive/MyDrive/MyFolder/Rag'\")\n",
        "        print(\"Change the line below to:\")\n",
        "        print(\"  rag_folder_path = '/content/drive/MyDrive/MyFolder/Rag'\")\n",
        "\n",
        "        # You can manually set the path here if needed\n",
        "        # rag_folder_path = \"/content/drive/MyDrive/YourActualFolderName\"\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Load documents\n",
        "        print(\"\\n📁 Loading documents from Google Drive...\")\n",
        "        documents = rag_system.load_documents_from_path(rag_folder_path)\n",
        "\n",
        "        # Create vector store\n",
        "        print(\"\\n🔍 Creating vector store...\")\n",
        "        rag_system.create_vector_store(documents)\n",
        "\n",
        "        # Setup RAG chain\n",
        "        print(\"\\n⚙️ Setting up RAG chain...\")\n",
        "        rag_system.setup_rag_chain()\n",
        "\n",
        "        # Test with queries\n",
        "        test_queries = [\n",
        "            \"What is the primary goal of the SELF-ROUTE method proposed by Zhuowan Li?\",\n",
        "            \"Explain why the researchers believe RAG might still be useful despite the superior performance of long-context LLMs\",\n",
        "            \"Compare the reranking techniques mentioned in the Wang paper. How do they impact the retrieval quality?\",\n",
        "            \"What are the trade-offs involved when using different chunking strategies in RAG systems?\",\n",
        "            \"How does multimodal retrieval enhance the capabilities of RAG?\",\n",
        "            \"What were the key failure cases for RAG in handling long context retrievals, as noted by Zhuowan Li?\",\n",
        "            \"Why does the Zhuowan paper claim that long-context LLMs outperformed RAG in most cases? What benefits does RAG still offer?\",\n",
        "            \"Describe the metrics used to evaluate the different embedding models for RAG in Wang's paper\",\n",
        "            \"Discuss the implications of using self-reflection in routing queries between RAG and long-context LLMs\",\n",
        "            \"How does query rewriting contribute to the overall efficiency of RAG according to Wang's findings?\",\n",
        "            \"Compare the cost-efficiency and performance trade-offs between RAG and long-context language models (LC) as discussed in the Wang and Zhuowan Li papers. How do these methods balance the ability to handle large volumes of text with computational demands?\",\n",
        "            \"In terms of chunking methods in Wang's paper, what is the difference in performance between the best and second-best methods in Table 4?\",\n",
        "            \"What are the best approaches for the retrieval and reranking modules according to Table 11 in Wang paper?\"\n",
        "        ]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🚀 TESTING RAG SYSTEM\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for i, query in enumerate(test_queries, 1):\n",
        "            print(f\"\\n{'-'*60}\")\n",
        "            print(f\"📝 QUERY {i}: {query}\")\n",
        "            print(f\"{'-'*60}\")\n",
        "\n",
        "            try:\n",
        "                result = rag_system.query(query)\n",
        "                print(f\"\\n💡 ANSWER: {result['answer']}\")\n",
        "\n",
        "                print(f\"\\n📚 SOURCES:\")\n",
        "                for source in result['sources']:\n",
        "                    print(f\"  [{source['index']}] {source['source']}, Page {source['page']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ ERROR: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: {e}\")\n",
        "\n",
        "# Cell 7: Run the system\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Cell 8: Optional - Manual folder specification\n",
        "# If the automatic detection doesn't work, uncomment and modify this:\n",
        "\"\"\"\n",
        "# Manual setup if automatic detection fails\n",
        "rag_system = ColabDriveRAG(OPENAI_KEY)\n",
        "\n",
        "# Replace this path with your actual folder path\n",
        "manual_folder_path = \"/content/drive/MyDrive/Rag\"\n",
        "\n",
        "try:\n",
        "    documents = rag_system.load_documents_from_path(manual_folder_path)\n",
        "    rag_system.create_vector_store(documents)\n",
        "    rag_system.setup_rag_chain()\n",
        "\n",
        "    # Test a single query\n",
        "    result = rag_system.query(\"What is the main topic of these documents?\")\n",
        "    print(f\"Answer: {result['answer']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
