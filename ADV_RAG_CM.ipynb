{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d60f9b92e0c4a2cb675e8c1559667ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69ccea43f6424c25a4afd2f517b95108",
              "IPY_MODEL_44b150db84e04b4f8e6cec838f0039ee",
              "IPY_MODEL_9e2628d19a6f409894c58cdc3e88c91c"
            ],
            "layout": "IPY_MODEL_bf7142b1bc2e4ba3bab17d617dfdd5f8"
          }
        },
        "69ccea43f6424c25a4afd2f517b95108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7de7887e0a4e4585537124c2b9f09f",
            "placeholder": "​",
            "style": "IPY_MODEL_a341e4e3e5784ca7a621767d0d5185be",
            "value": "Batches: 100%"
          }
        },
        "44b150db84e04b4f8e6cec838f0039ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f23a0491ed4c37badffcc87825251e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e843adb48e9c481ea730e556aac7729c",
            "value": 2
          }
        },
        "9e2628d19a6f409894c58cdc3e88c91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9f5c7667214b4a9257bf582e7e6028",
            "placeholder": "​",
            "style": "IPY_MODEL_2f69fd687b27409e83d7942f4557cdac",
            "value": " 2/2 [01:57&lt;00:00, 58.26s/it]"
          }
        },
        "bf7142b1bc2e4ba3bab17d617dfdd5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7de7887e0a4e4585537124c2b9f09f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a341e4e3e5784ca7a621767d0d5185be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f23a0491ed4c37badffcc87825251e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e843adb48e9c481ea730e556aac7729c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b9f5c7667214b4a9257bf582e7e6028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f69fd687b27409e83d7942f4557cdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f09ba83622b4238b44c5e70d2b32214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9063b77c85f443aaa16aa58da71d1f0b",
              "IPY_MODEL_48020990585a4a17b224e8419a4d33df",
              "IPY_MODEL_60abcc6077094eec80dbae22eb714405"
            ],
            "layout": "IPY_MODEL_f521d614f4ce41a39a8d0c1680191f85"
          }
        },
        "9063b77c85f443aaa16aa58da71d1f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f2d2707af6453e8c992cff4fc1ea3a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff7ac39572494e62bb4134fbbeced036",
            "value": "Batches: 100%"
          }
        },
        "48020990585a4a17b224e8419a4d33df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3633c7f4fffa4bd393a27b3d033de1e7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9599bee3c014abd8ba3e08207e34e43",
            "value": 2
          }
        },
        "60abcc6077094eec80dbae22eb714405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d618bef72a64a4783465c3afd6b05f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e058ac47ecd54d13b1a0dae351ab9302",
            "value": " 2/2 [02:11&lt;00:00, 64.89s/it]"
          }
        },
        "f521d614f4ce41a39a8d0c1680191f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f2d2707af6453e8c992cff4fc1ea3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7ac39572494e62bb4134fbbeced036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3633c7f4fffa4bd393a27b3d033de1e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9599bee3c014abd8ba3e08207e34e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d618bef72a64a4783465c3afd6b05f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e058ac47ecd54d13b1a0dae351ab9302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# First, install additional dependencies\n",
        "!pip install sentence-transformers[train] datasets accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHEKohaywjmt",
        "outputId": "b210bc75-db51-4bf3-c42c-44a512184186"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: sentence-transformers[train] in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (4.53.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (0.33.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers[train]) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers[train]) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.7.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers[train])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers[train]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers[train]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers[train]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers[train]) (0.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers[train]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers[train]) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers[train]) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu PyPDF2 torch openai python-dotenv\n",
        "!pip install --upgrade langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8BYHKPKhxU9",
        "outputId": "cb35077a-c5b4-48af-856e-b3eb22b70018"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.94.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-dotenv-1.1.1\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.9)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import PyPDF2\n",
        "import faiss\n",
        "import torch\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jkphoIlP60J0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "8XXN3ZTt62lg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your existing classes (keeping them as they work well)\n",
        "class DocumentProcessor:\n",
        "    def __init__(self):\n",
        "        self.documents = {}\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page_num, page in enumerate(pdf_reader.pages):\n",
        "                    page_text = page.extract_text()\n",
        "                    page_text = self.enhance_table_extraction(page_text)\n",
        "                    text += f\"\\nPage {page_num + 1}: {page_text}\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "        return text\n",
        "\n",
        "    def enhance_table_extraction(self, text: str) -> str:\n",
        "        lines = text.split('\\n')\n",
        "        processed_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            if re.search(r'(self-route|routing|self-reflection)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"SELF_ROUTE_CONTENT: {line}\")\n",
        "            elif re.search(r'(failure|error).*(type|case|category)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"FAILURE_TYPES: {line}\")\n",
        "            elif re.search(r'(multi-step|general knowledge|implicit|long.?complex)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"FAILURE_DETAIL: {line}\")\n",
        "            elif re.search(r'(mrr|recall@|ndcg@|precision|f1)', line, re.IGNORECASE):\n",
        "                line = re.sub(r'\\s+', ' | ', line)\n",
        "                processed_lines.append(f\"METRICS_TABLE: {line}\")\n",
        "            elif re.search(r'(chunk|segment|overlap|window)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"CHUNKING_STRATEGY: {line}\")\n",
        "            elif re.search(r'(outperform|superior|better|vs|versus|comparison)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"PERFORMANCE_COMPARISON: {line}\")\n",
        "            elif re.search(r'(goal|objective|aim|purpose|method)', line, re.IGNORECASE):\n",
        "                processed_lines.append(f\"METHOD_GOAL: {line}\")\n",
        "            else:\n",
        "                processed_lines.append(line)\n",
        "\n",
        "        return '\\n'.join(processed_lines)\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
        "        text = re.sub(r'[ \\t]+', ' ', text)\n",
        "        text = re.sub(r'([.!?])\\s+([A-Z])', r'\\1\\n\\2', text)\n",
        "        text = re.sub(r'[^\\w\\s.,;:!?()\\%@\\-\\[\\]{}|]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def upload_and_process_pdfs(self) -> Dict[str, str]:\n",
        "        print(\"Please upload your PDF files:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename, content in uploaded.items():\n",
        "            if filename.endswith('.pdf'):\n",
        "                with open(filename, 'wb') as f:\n",
        "                    f.write(content)\n",
        "\n",
        "                text = self.extract_text_from_pdf(filename)\n",
        "                cleaned_text = self.clean_text(text)\n",
        "                self.documents[filename] = cleaned_text\n",
        "                print(f\"✅ Processed {filename}: {len(cleaned_text)} characters\")\n",
        "\n",
        "        return self.documents\n",
        "\n",
        "class TextChunker:\n",
        "    def __init__(self, chunk_size: int = 512, overlap: int = 100):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def chunk_text(self, text: str, document_name: str) -> List[Dict]:\n",
        "        paragraphs = text.split('\\n\\n')\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "        word_count = 0\n",
        "\n",
        "        for para in paragraphs:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence_words = sentence.split()\n",
        "\n",
        "                if word_count + len(sentence_words) > self.chunk_size and current_chunk:\n",
        "                    chunks.append({\n",
        "                        'text': current_chunk.strip(),\n",
        "                        'document': document_name,\n",
        "                        'chunk_id': len(chunks),\n",
        "                        'word_count': word_count\n",
        "                    })\n",
        "\n",
        "                    overlap_text = ' '.join(current_chunk.split()[-self.overlap:])\n",
        "                    current_chunk = overlap_text + \" \" + sentence\n",
        "                    word_count = len(current_chunk.split())\n",
        "                else:\n",
        "                    current_chunk += \" \" + sentence\n",
        "                    word_count += len(sentence_words)\n",
        "\n",
        "        if current_chunk.strip():\n",
        "            chunks.append({\n",
        "                'text': current_chunk.strip(),\n",
        "                'document': document_name,\n",
        "                'chunk_id': len(chunks),\n",
        "                'word_count': word_count\n",
        "            })\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def chunk_documents(self, documents: Dict[str, str]) -> List[Dict]:\n",
        "        all_chunks = []\n",
        "        for doc_name, text in documents.items():\n",
        "            chunks = self.chunk_text(text, doc_name)\n",
        "            all_chunks.extend(chunks)\n",
        "\n",
        "        print(f\"✅ Created {len(all_chunks)} chunks total\")\n",
        "        return all_chunks\n",
        "\n",
        "# Simplified embedding manager - NO FINE-TUNING\n",
        "class SimpleEmbeddingManager:\n",
        "    \"\"\"Simple embedding manager with no fine-tuning - just different base models\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.embeddings = None\n",
        "        self.chunks = None\n",
        "        self.index = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the model\"\"\"\n",
        "        print(f\"🔄 Loading model: {self.model_name}\")\n",
        "        self.model = SentenceTransformer(self.model_name)\n",
        "        print(\"✅ Model loaded successfully\")\n",
        "\n",
        "    def create_embeddings(self, chunks: List[Dict]) -> np.ndarray:\n",
        "        \"\"\"Create embeddings for chunks\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "\n",
        "        texts = [chunk['text'] for chunk in chunks]\n",
        "        embeddings = self.model.encode(texts, show_progress_bar=True, batch_size=32)\n",
        "\n",
        "        self.chunks = chunks\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "        # Create FAISS index for fast similarity search\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "        # Normalize embeddings for cosine similarity\n",
        "        embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "        self.index.add(embeddings_normalized.astype('float32'))\n",
        "\n",
        "        print(f\"✅ Created {len(embeddings)} embeddings with {self.model_name} (dim: {dimension})\")\n",
        "        return embeddings\n",
        "\n",
        "    def retrieve_relevant_chunks(self, query: str, top_k: int = 8) -> List[Dict]:\n",
        "        \"\"\"Retrieve relevant chunks using semantic similarity\"\"\"\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Index not created. Please create embeddings first.\")\n",
        "\n",
        "        # Encode query\n",
        "        query_embedding = self.model.encode([query])\n",
        "        query_normalized = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "        # Search for similar chunks\n",
        "        scores, indices = self.index.search(query_normalized.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        for score, idx in zip(scores[0], indices[0]):\n",
        "            if idx < len(self.chunks):\n",
        "                chunk = self.chunks[idx].copy()\n",
        "                chunk['similarity_score'] = float(score)\n",
        "                results.append(chunk)\n",
        "\n",
        "        return results\n",
        "\n",
        "# Evaluation system for measuring improvement\n",
        "class RetrievalEvaluator:\n",
        "    \"\"\"Evaluate retrieval performance using standard IR metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.test_queries = [\n",
        "            \"What is the primary goal of the SELF-ROUTE method proposed by Zhuowan Li?\",\n",
        "            \"Explain why the researchers believe RAG might still be useful despite the superior performance of long-context LLMs\",\n",
        "            \"Compare the reranking techniques mentioned in the Wang paper. How do they impact the retrieval quality?\",\n",
        "            \"What are the trade-offs involved when using different chunking strategies in RAG systems?\",\n",
        "            \"How does multimodal retrieval enhance the capabilities of RAG?\",\n",
        "            \"What were the key failure cases for RAG in handling long context retrievals, as noted by Zhuowan Li?\",\n",
        "            \"Why does the Zhuowan paper claim that long-context LLMs outperformed RAG in most cases? What benefits does RAG still offer?\",\n",
        "            \"Describe the metrics used to evaluate the different embedding models for RAG in Wang's paper\",\n",
        "            \"Discuss the implications of using self-reflection in routing queries between RAG and long-context LLMs\",\n",
        "            \"How does query rewriting contribute to the overall efficiency of RAG according to Wang's findings?\",\n",
        "            \"Compare the cost-efficiency and performance trade-offs between RAG and long-context language models (LC) as discussed in the Wang and Zhuowan Li papers. How do these methods balance the ability to handle large volumes of text with computational demands?\",\n",
        "            \"In terms of chunking methods in Wang's paper, what is the difference in performance between the best and second-best methods in Table 4?\",\n",
        "            \"What are the best approaches for the retrieval and reranking modules according to Table 11 in Wang paper?\"\n",
        "        ]\n",
        "\n",
        "    def evaluate_system(self, embedding_manager: SimpleEmbeddingManager,\n",
        "                       system_name: str = \"RAG System\") -> Dict:\n",
        "        \"\"\"Evaluate the RAG system using retrieval metrics\"\"\"\n",
        "\n",
        "        print(f\"📊 Evaluating {system_name}...\")\n",
        "\n",
        "        results = {\n",
        "            'system_name': system_name,\n",
        "            'queries': [],\n",
        "            'avg_similarity': 0.0,\n",
        "            'top_1_scores': [],\n",
        "            'top_3_avg_scores': [],\n",
        "            'retrieval_success_rate': 0.0\n",
        "        }\n",
        "\n",
        "        total_similarity = 0.0\n",
        "        successful_retrievals = 0\n",
        "\n",
        "        for i, query in enumerate(self.test_queries):\n",
        "            try:\n",
        "                chunks = embedding_manager.retrieve_relevant_chunks(query, top_k=5)\n",
        "\n",
        "                if chunks:\n",
        "                    top_1_score = chunks[0]['similarity_score']\n",
        "                    top_3_avg = np.mean([c['similarity_score'] for c in chunks[:3]])\n",
        "\n",
        "                    results['queries'].append({\n",
        "                        'query': query,\n",
        "                        'top_1_score': top_1_score,\n",
        "                        'top_3_avg': top_3_avg,\n",
        "                        'num_results': len(chunks)\n",
        "                    })\n",
        "\n",
        "                    results['top_1_scores'].append(top_1_score)\n",
        "                    results['top_3_avg_scores'].append(top_3_avg)\n",
        "                    total_similarity += top_1_score\n",
        "\n",
        "                    # Consider retrieval successful if top score > 0.3\n",
        "                    if top_1_score > 0.3:\n",
        "                        successful_retrievals += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error evaluating query {i+1}: {e}\")\n",
        "\n",
        "        # Calculate aggregate metrics\n",
        "        if results['top_1_scores']:\n",
        "            results['avg_similarity'] = total_similarity / len(results['top_1_scores'])\n",
        "            results['retrieval_success_rate'] = successful_retrievals / len(results['top_1_scores'])\n",
        "\n",
        "        self._print_evaluation_results(results)\n",
        "        return results\n",
        "\n",
        "    def _print_evaluation_results(self, results: Dict):\n",
        "        \"\"\"Print formatted evaluation results\"\"\"\n",
        "        print(f\"\\n📊 EVALUATION RESULTS: {results['system_name']}\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Average Top-1 Similarity: {results['avg_similarity']:.4f}\")\n",
        "        print(f\"Retrieval Success Rate: {results['retrieval_success_rate']:.2%}\")\n",
        "\n",
        "        if results['top_1_scores']:\n",
        "            print(f\"Best Query Score: {max(results['top_1_scores']):.4f}\")\n",
        "            print(f\"Worst Query Score: {min(results['top_1_scores']):.4f}\")\n",
        "            print(f\"Total Queries Evaluated: {len(results['top_1_scores'])}\")\n",
        "\n",
        "        # Show per-query breakdown for detailed analysis\n",
        "        print(f\"\\n📋 PER-QUERY BREAKDOWN:\")\n",
        "        for i, query_result in enumerate(results['queries'], 1):\n",
        "            query_short = query_result['query'][:60] + \"...\" if len(query_result['query']) > 60 else query_result['query']\n",
        "            print(f\"{i:2d}. Score: {query_result['top_1_score']:.3f} | {query_short}\")\n",
        "\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "# Simple RAG system with model comparison (NO FINE-TUNING)\n",
        "class SimpleRAGComparison:\n",
        "    \"\"\"Simple RAG system that compares different base models\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.base_embedding_manager = None\n",
        "        self.enhanced_embedding_manager = None\n",
        "        self.documents = {}\n",
        "        self.chunks = []\n",
        "\n",
        "    def setup_documents(self, documents: Dict[str, str]):\n",
        "        \"\"\"Setup documents and prepare for comparison\"\"\"\n",
        "        self.documents = documents\n",
        "\n",
        "        # Create chunks\n",
        "        chunker = TextChunker(chunk_size=400, overlap=80)\n",
        "        self.chunks = chunker.chunk_documents(documents)\n",
        "\n",
        "        # Setup base system (MPNet)\n",
        "        print(\"🔧 Setting up base embedding system (MPNet)...\")\n",
        "        self.base_embedding_manager = SimpleEmbeddingManager(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "        self.base_embedding_manager.create_embeddings(self.chunks)\n",
        "\n",
        "        # Setup enhanced system (BGE)\n",
        "        print(\"🔧 Setting up enhanced embedding system (BGE)...\")\n",
        "        self.enhanced_embedding_manager = SimpleEmbeddingManager(\"BAAI/bge-base-en-v1.5\")\n",
        "        self.enhanced_embedding_manager.create_embeddings(self.chunks)\n",
        "\n",
        "        print(\"✅ Both RAG systems ready!\")\n",
        "\n",
        "    def compare_systems(self) -> Dict:\n",
        "        \"\"\"Compare base vs enhanced systems\"\"\"\n",
        "        evaluator = RetrievalEvaluator()\n",
        "\n",
        "        # Evaluate base system\n",
        "        base_results = evaluator.evaluate_system(self.base_embedding_manager, \"Base System (MPNet)\")\n",
        "\n",
        "        # Evaluate enhanced system\n",
        "        enhanced_results = evaluator.evaluate_system(self.enhanced_embedding_manager, \"Enhanced System (BGE)\")\n",
        "\n",
        "        results = {\n",
        "            'base': base_results,\n",
        "            'enhanced': enhanced_results\n",
        "        }\n",
        "\n",
        "        # Calculate improvement\n",
        "        improvement = enhanced_results['avg_similarity'] - base_results['avg_similarity']\n",
        "        improvement_pct = (improvement / base_results['avg_similarity']) * 100 if base_results['avg_similarity'] > 0 else 0\n",
        "\n",
        "        print(f\"\\n🎯 IMPROVEMENT SUMMARY:\")\n",
        "        print(f\"Absolute Improvement: +{improvement:.4f}\")\n",
        "        print(f\"Relative Improvement: +{improvement_pct:.1f}%\")\n",
        "\n",
        "        results['improvement'] = {\n",
        "            'absolute': improvement,\n",
        "            'relative_pct': improvement_pct\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_answer(self, query: str, use_enhanced: bool = True) -> Dict:\n",
        "        \"\"\"Generate answer using specified system\"\"\"\n",
        "        manager = self.enhanced_embedding_manager if use_enhanced else self.base_embedding_manager\n",
        "\n",
        "        try:\n",
        "            chunks = manager.retrieve_relevant_chunks(query, top_k=5)\n",
        "            answer = self._create_answer_from_chunks(query, chunks)\n",
        "\n",
        "            return {\n",
        "                'query': query,\n",
        "                'answer': answer,\n",
        "                'chunks': chunks,\n",
        "                'system_used': 'enhanced' if use_enhanced else 'base'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'query': query,\n",
        "                'answer': f\"Error: {str(e)}\",\n",
        "                'chunks': [],\n",
        "                'system_used': 'error'\n",
        "            }\n",
        "\n",
        "    def _create_answer_from_chunks(self, query: str, chunks: List[Dict]) -> str:\n",
        "        \"\"\"Create answer from retrieved chunks\"\"\"\n",
        "        if not chunks:\n",
        "            return \"No relevant information found.\"\n",
        "\n",
        "        # Combine top chunks\n",
        "        combined_text = \" \".join([chunk['text'] for chunk in chunks[:3]])\n",
        "\n",
        "        # Simple extractive approach\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', combined_text)\n",
        "        query_words = set(query.lower().split())\n",
        "\n",
        "        scored_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if len(sentence.strip()) < 20:\n",
        "                continue\n",
        "\n",
        "            sentence_words = set(sentence.lower().split())\n",
        "            overlap = len(query_words.intersection(sentence_words))\n",
        "\n",
        "            # Bonus for academic terms\n",
        "            if any(term in sentence.lower() for term in ['rag', 'retrieval', 'embedding', 'method', 'performance']):\n",
        "                overlap += 2\n",
        "\n",
        "            if overlap > 0:\n",
        "                scored_sentences.append((overlap, sentence.strip()))\n",
        "\n",
        "        if scored_sentences:\n",
        "            scored_sentences.sort(reverse=True, key=lambda x: x[0])\n",
        "            top_sentences = [sent for _, sent in scored_sentences[:2]]\n",
        "            return \". \".join(top_sentences) + \".\"\n",
        "\n",
        "        return \"Based on the retrieved information: \" + combined_text[:200] + \"...\"\n",
        "\n",
        "# Simple demo function\n",
        "def run_simple_rag_comparison():\n",
        "    \"\"\"Run simple RAG comparison without fine-tuning\"\"\"\n",
        "    print(\"🚀 Starting Simple RAG Model Comparison\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Upload and process documents\n",
        "    doc_processor = DocumentProcessor()\n",
        "    documents = doc_processor.upload_and_process_pdfs()\n",
        "\n",
        "    if not documents:\n",
        "        print(\"❌ No documents uploaded.\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Setup systems\n",
        "    rag_system = SimpleRAGComparison()\n",
        "    rag_system.setup_documents(documents)\n",
        "\n",
        "    # Step 3: Compare systems\n",
        "    comparison_results = rag_system.compare_systems()\n",
        "\n",
        "    # Step 4: Test both systems on ALL queries\n",
        "    test_queries = comparison_results['base']['queries'] if 'base' in comparison_results else []\n",
        "\n",
        "    print(f\"\\n💬 Testing All {len(test_queries)} Queries:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    detailed_results = []\n",
        "\n",
        "    for i, query_data in enumerate(test_queries, 1):\n",
        "        query = query_data['query']\n",
        "        print(f\"\\n🔍 Query {i}: {query}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Test base system\n",
        "        base_result = rag_system.generate_answer(query, use_enhanced=False)\n",
        "        base_score = base_result['chunks'][0]['similarity_score'] if base_result['chunks'] else 0.0\n",
        "\n",
        "        # Test enhanced system\n",
        "        enhanced_result = rag_system.generate_answer(query, use_enhanced=True)\n",
        "        enhanced_score = enhanced_result['chunks'][0]['similarity_score'] if enhanced_result['chunks'] else 0.0\n",
        "\n",
        "        # Calculate improvement\n",
        "        improvement = enhanced_score - base_score\n",
        "        improvement_pct = (improvement / base_score * 100) if base_score > 0 else 0\n",
        "\n",
        "        print(f\"📊 Similarity Scores:\")\n",
        "        print(f\"   Base System (MPNet):  {base_score:.4f}\")\n",
        "        print(f\"   Enhanced System (BGE): {enhanced_score:.4f}\")\n",
        "        print(f\"   Improvement:          +{improvement:.4f} ({improvement_pct:+.1f}%)\")\n",
        "\n",
        "        print(f\"\\n📄 Base Answer: {base_result['answer'][:200]}...\")\n",
        "        print(f\"\\n🚀 Enhanced Answer: {enhanced_result['answer'][:200]}...\")\n",
        "\n",
        "        detailed_results.append({\n",
        "            'query_id': i,\n",
        "            'query': query,\n",
        "            'base_score': base_score,\n",
        "            'enhanced_score': enhanced_score,\n",
        "            'improvement': improvement,\n",
        "            'improvement_pct': improvement_pct,\n",
        "            'base_answer': base_result['answer'],\n",
        "            'enhanced_answer': enhanced_result['answer']\n",
        "        })\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    # Summary statistics\n",
        "    if detailed_results:\n",
        "        avg_base = np.mean([r['base_score'] for r in detailed_results])\n",
        "        avg_enhanced = np.mean([r['enhanced_score'] for r in detailed_results])\n",
        "        avg_improvement = avg_enhanced - avg_base\n",
        "        avg_improvement_pct = (avg_improvement / avg_base * 100) if avg_base > 0 else 0\n",
        "\n",
        "        print(f\"\\n📈 OVERALL SUMMARY:\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Average Base Score (MPNet):  {avg_base:.4f}\")\n",
        "        print(f\"Average Enhanced Score (BGE): {avg_enhanced:.4f}\")\n",
        "        print(f\"Average Improvement:         +{avg_improvement:.4f} ({avg_improvement_pct:+.1f}%)\")\n",
        "\n",
        "        # Best improvements\n",
        "        best_improvements = sorted(detailed_results, key=lambda x: x['improvement_pct'], reverse=True)[:3]\n",
        "        print(f\"\\n🏆 TOP 3 IMPROVEMENTS:\")\n",
        "        for j, result in enumerate(best_improvements, 1):\n",
        "            print(f\"{j}. Query {result['query_id']}: {result['improvement_pct']:+.1f}% improvement\")\n",
        "            print(f\"   {result['query'][:80]}...\")\n",
        "\n",
        "        # Save detailed results\n",
        "        results_df = pd.DataFrame(detailed_results)\n",
        "        results_df.to_csv('simple_model_comparison.csv', index=False)\n",
        "        print(f\"\\n💾 Detailed results saved to 'simple_model_comparison.csv'\")\n",
        "\n",
        "        comparison_results['detailed_query_results'] = detailed_results\n",
        "\n",
        "    return rag_system, comparison_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Simple RAG Model Comparison Ready!\")\n",
        "    print(\"Run: rag_system, results = run_simple_rag_comparison()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fz14EuN6x1M",
        "outputId": "99699e4e-ace7-4430-c76a-993111fead82"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple RAG Model Comparison Ready!\n",
            "Run: rag_system, results = run_simple_rag_comparison()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = run_simple_rag_comparison()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2d60f9b92e0c4a2cb675e8c1559667ab",
            "69ccea43f6424c25a4afd2f517b95108",
            "44b150db84e04b4f8e6cec838f0039ee",
            "9e2628d19a6f409894c58cdc3e88c91c",
            "bf7142b1bc2e4ba3bab17d617dfdd5f8",
            "7d7de7887e0a4e4585537124c2b9f09f",
            "a341e4e3e5784ca7a621767d0d5185be",
            "f8f23a0491ed4c37badffcc87825251e",
            "e843adb48e9c481ea730e556aac7729c",
            "3b9f5c7667214b4a9257bf582e7e6028",
            "2f69fd687b27409e83d7942f4557cdac",
            "3f09ba83622b4238b44c5e70d2b32214",
            "9063b77c85f443aaa16aa58da71d1f0b",
            "48020990585a4a17b224e8419a4d33df",
            "60abcc6077094eec80dbae22eb714405",
            "f521d614f4ce41a39a8d0c1680191f85",
            "15f2d2707af6453e8c992cff4fc1ea3a",
            "ff7ac39572494e62bb4134fbbeced036",
            "3633c7f4fffa4bd393a27b3d033de1e7",
            "c9599bee3c014abd8ba3e08207e34e43",
            "2d618bef72a64a4783465c3afd6b05f0",
            "e058ac47ecd54d13b1a0dae351ab9302"
          ]
        },
        "id": "ygPy4ZKj65v-",
        "outputId": "2ff3a258-cb53-4bcb-9968-c3dee496ce73"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Simple RAG Model Comparison\n",
            "============================================================\n",
            "Please upload your PDF files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3f253e0-3a38-4f9e-ae7f-72a7a1bc41e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3f253e0-3a38-4f9e-ae7f-72a7a1bc41e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2407.pdf to 2407 (7).pdf\n",
            "✅ Processed 2407 (7).pdf: 127122 characters\n",
            "✅ Created 62 chunks total\n",
            "🔧 Setting up base embedding system (MPNet)...\n",
            "🔄 Loading model: sentence-transformers/all-mpnet-base-v2\n",
            "✅ Model loaded successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d60f9b92e0c4a2cb675e8c1559667ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created 62 embeddings with sentence-transformers/all-mpnet-base-v2 (dim: 768)\n",
            "🔧 Setting up enhanced embedding system (BGE)...\n",
            "🔄 Loading model: BAAI/bge-base-en-v1.5\n",
            "✅ Model loaded successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f09ba83622b4238b44c5e70d2b32214"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created 62 embeddings with BAAI/bge-base-en-v1.5 (dim: 768)\n",
            "✅ Both RAG systems ready!\n",
            "📊 Evaluating Base System (MPNet)...\n",
            "\n",
            "📊 EVALUATION RESULTS: Base System (MPNet)\n",
            "==================================================\n",
            "Average Top-1 Similarity: 0.6151\n",
            "Retrieval Success Rate: 100.00%\n",
            "Best Query Score: 0.7465\n",
            "Worst Query Score: 0.3508\n",
            "Total Queries Evaluated: 13\n",
            "\n",
            "📋 PER-QUERY BREAKDOWN:\n",
            " 1. Score: 0.351 | What is the primary goal of the SELF-ROUTE method proposed b...\n",
            " 2. Score: 0.704 | Explain why the researchers believe RAG might still be usefu...\n",
            " 3. Score: 0.726 | Compare the reranking techniques mentioned in the Wang paper...\n",
            " 4. Score: 0.472 | What are the trade-offs involved when using different chunki...\n",
            " 5. Score: 0.630 | How does multimodal retrieval enhance the capabilities of RA...\n",
            " 6. Score: 0.662 | What were the key failure cases for RAG in handling long con...\n",
            " 7. Score: 0.639 | Why does the Zhuowan paper claim that long-context LLMs outp...\n",
            " 8. Score: 0.482 | Describe the metrics used to evaluate the different embeddin...\n",
            " 9. Score: 0.747 | Discuss the implications of using self-reflection in routing...\n",
            "10. Score: 0.624 | How does query rewriting contribute to the overall efficienc...\n",
            "11. Score: 0.741 | Compare the cost-efficiency and performance trade-offs betwe...\n",
            "12. Score: 0.586 | In terms of chunking methods in Wang's paper, what is the di...\n",
            "13. Score: 0.631 | What are the best approaches for the retrieval and reranking...\n",
            "==================================================\n",
            "📊 Evaluating Enhanced System (BGE)...\n",
            "\n",
            "📊 EVALUATION RESULTS: Enhanced System (BGE)\n",
            "==================================================\n",
            "Average Top-1 Similarity: 0.7996\n",
            "Retrieval Success Rate: 100.00%\n",
            "Best Query Score: 0.8879\n",
            "Worst Query Score: 0.6430\n",
            "Total Queries Evaluated: 13\n",
            "\n",
            "📋 PER-QUERY BREAKDOWN:\n",
            " 1. Score: 0.643 | What is the primary goal of the SELF-ROUTE method proposed b...\n",
            " 2. Score: 0.861 | Explain why the researchers believe RAG might still be usefu...\n",
            " 3. Score: 0.828 | Compare the reranking techniques mentioned in the Wang paper...\n",
            " 4. Score: 0.769 | What are the trade-offs involved when using different chunki...\n",
            " 5. Score: 0.809 | How does multimodal retrieval enhance the capabilities of RA...\n",
            " 6. Score: 0.818 | What were the key failure cases for RAG in handling long con...\n",
            " 7. Score: 0.782 | Why does the Zhuowan paper claim that long-context LLMs outp...\n",
            " 8. Score: 0.800 | Describe the metrics used to evaluate the different embeddin...\n",
            " 9. Score: 0.837 | Discuss the implications of using self-reflection in routing...\n",
            "10. Score: 0.793 | How does query rewriting contribute to the overall efficienc...\n",
            "11. Score: 0.888 | Compare the cost-efficiency and performance trade-offs betwe...\n",
            "12. Score: 0.770 | In terms of chunking methods in Wang's paper, what is the di...\n",
            "13. Score: 0.798 | What are the best approaches for the retrieval and reranking...\n",
            "==================================================\n",
            "\n",
            "🎯 IMPROVEMENT SUMMARY:\n",
            "Absolute Improvement: +0.1845\n",
            "Relative Improvement: +30.0%\n",
            "\n",
            "💬 Testing All 13 Queries:\n",
            "============================================================\n",
            "\n",
            "🔍 Query 1: What is the primary goal of the SELF-ROUTE method proposed by Zhuowan Li?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.3508\n",
            "   Enhanced System (BGE): 0.6430\n",
            "   Improvement:          +0.2922 (+83.3%)\n",
            "\n",
            "📄 Base Answer: METHOD_GOAL: On longer datasets, the advantage of our method\n",
            "is more pronounced for OpenAI models, but less\n",
            "significant for Gemini.. Rows -5 display the percentage\n",
            "METHOD_GOAL: of tokens used by our m...\n",
            "\n",
            "🚀 Enhanced Answer: Our proposed method, which dynamically SELF_ROUTE_CONTENT: routes queries based on model self-reflection, ef- fectively combines the strengths of both RAG and LC, achieving comparable performance to L...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 2: Explain why the researchers believe RAG might still be useful despite the superior performance of long-context LLMs\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.7041\n",
            "   Enhanced System (BGE): 0.8609\n",
            "   Improvement:          +0.1568 (+22.3%)\n",
            "\n",
            "📄 Base Answer: While recent LLMs like Gemini-1.5 (Reid et al., 2024), GPT-4 (Achiam et al., 2023), Claude- 3 (Anthropic, 2024) achieve significantly larger CHUNKING_STRATEGY: context window size, long-context prompt...\n",
            "\n",
            "🚀 Enhanced Answer: While recent LLMs like Gemini-1.5 (Reid et al., 2024), GPT-4 (Achiam et al., 2023), Claude- 3 (Anthropic, 2024) achieve significantly larger CHUNKING_STRATEGY: context window size, long-context prompt...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 3: Compare the reranking techniques mentioned in the Wang paper. How do they impact the retrieval quality?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.7262\n",
            "   Enhanced System (BGE): 0.8279\n",
            "   Improvement:          +0.1016 (+14.0%)\n",
            "\n",
            "📄 Base Answer: 3.4.3 Hybrid Search with Different Weight on Sparse Retrieval\n",
            "Table 8 presents the impact of different αvalues in hybrid search, where αcontrols the weighting\n",
            "between sparse retrieval and dense retrie...\n",
            "\n",
            "🚀 Enhanced Answer: 3.4.3 Hybrid Search with Different Weight on Sparse Retrieval\n",
            "Table 8 presents the impact of different αvalues in hybrid search, where αcontrols the weighting\n",
            "between sparse retrieval and dense retrie...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 4: What are the trade-offs involved when using different chunking strategies in RAG systems?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.4725\n",
            "   Enhanced System (BGE): 0.7686\n",
            "   Improvement:          +0.2961 (+62.7%)\n",
            "\n",
            "📄 Base Answer: These\n",
            "different behaviors are possibly due to the differ-\n",
            "ence in LLM alignments, i.e., OpenAI models are\n",
            "more likely to reject answering using RAG, leading\n",
            "to a lower answerable percentage but higher...\n",
            "\n",
            "🚀 Enhanced Answer: These\n",
            "different behaviors are possibly due to the differ-\n",
            "ence in LLM alignments, i.e., OpenAI models are\n",
            "more likely to reject answering using RAG, leading\n",
            "to a lower answerable percentage but higher...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 5: How does multimodal retrieval enhance the capabilities of RAG?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.6301\n",
            "   Enhanced System (BGE): 0.8086\n",
            "   Improvement:          +0.1785 (+28.3%)\n",
            "\n",
            "📄 Base Answer: We demonstrate that the integration of multimodal retrieval techniques can substantially improve\n",
            "question-answering capabilities on visual inputs and speed up the generation of multimodal content\n",
            "thro...\n",
            "\n",
            "🚀 Enhanced Answer: Moreover,\n",
            "we demonstrate that multimodal retrieval techniques can significantly enhance\n",
            "question-answering capabilities about visual inputs and accelerate the generation\n",
            "of multimodal content using a ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 6: What were the key failure cases for RAG in handling long context retrievals, as noted by Zhuowan Li?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.6623\n",
            "   Enhanced System (BGE): 0.8178\n",
            "   Improvement:          +0.1554 (+23.5%)\n",
            "\n",
            "📄 Base Answer: As can be seen, the results are consistent with Contriever, for all SELF_ROUTE_CONTENT: of LC, RAG, and SELF-ROUTE , showing that our findings are generalizable across retrievers.5.4 Results on synthe...\n",
            "\n",
            "🚀 Enhanced Answer: RAG retrieves relevant informa-\n",
            "tion based on the query and then prompts an LLM\n",
            "to generate a response in the context of the retrieved\n",
            "information.. and RAG: on one hand, RAG conceptually acts as\n",
            "a pr...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 7: Why does the Zhuowan paper claim that long-context LLMs outperformed RAG in most cases? What benefits does RAG still offer?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.6392\n",
            "   Enhanced System (BGE): 0.7823\n",
            "   Improvement:          +0.1431 (+22.4%)\n",
            "\n",
            "📄 Base Answer: We believe our findings contribute valuable insights for the practical appli- cation of long-context LLMs and pave the way for future research in optimizing RAG techniques.. on average, k 5has the low...\n",
            "\n",
            "🚀 Enhanced Answer: While recent LLMs like Gemini-1.5 (Reid et al., 2024), GPT-4 (Achiam et al., 2023), Claude- 3 (Anthropic, 2024) achieve significantly larger CHUNKING_STRATEGY: context window size, long-context prompt...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 8: Describe the metrics used to evaluate the different embedding models for RAG in Wang's paper\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.4824\n",
            "   Enhanced System (BGE): 0.7998\n",
            "   Improvement:          +0.3174 (+65.8%)\n",
            "\n",
            "📄 Base Answer: This finding motivates us to leverage RAG for\n",
            "the majority of queries, reserving computationally\n",
            "more expensive LC for a small subset of queries\n",
            "where it truly excels.. 4 Searching for Best RAG Practi...\n",
            "\n",
            "🚀 Enhanced Answer: METHOD_GOAL: In this study, we aim to identify the best practices for RAG through extensive experimentation.. To the best of our knowledge, there has been no systematic effort to pursue the optimal im...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 9: Discuss the implications of using self-reflection in routing queries between RAG and long-context LLMs\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.7465\n",
            "   Enhanced System (BGE): 0.8374\n",
            "   Improvement:          +0.0908 (+12.2%)\n",
            "\n",
            "📄 Base Answer: In addition to\n",
            "quantitative evaluation, we provide a comprehen-\n",
            "sive analysis comparing RAG and LC, including\n",
            "common failure patterns of RAG, the trade-offs\n",
            "between cost and performance, and the resul...\n",
            "\n",
            "🚀 Enhanced Answer: We believe our findings contribute valuable insights for the practical appli- cation of long-context LLMs and pave the way for future research in optimizing RAG techniques.. In addition to\n",
            "quantitativ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 10: How does query rewriting contribute to the overall efficiency of RAG according to Wang's findings?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.6242\n",
            "   Enhanced System (BGE): 0.7932\n",
            "   Improvement:          +0.1690 (+27.1%)\n",
            "\n",
            "📄 Base Answer: The experimental results demonstrate that each module contributes uniquely to the overall perfor-\n",
            "mance of the RAG system.. 5 Discussion\n",
            "5.1 Best Practices for Implementing RAG\n",
            "According to our experi...\n",
            "\n",
            "🚀 Enhanced Answer: The experimental results demonstrate that each module contributes uniquely to the overall perfor-\n",
            "mance of the RAG system.. 5 Discussion\n",
            "5.1 Best Practices for Implementing RAG\n",
            "According to our experi...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 11: Compare the cost-efficiency and performance trade-offs between RAG and long-context language models (LC) as discussed in the Wang and Zhuowan Li papers. How do these methods balance the ability to handle large volumes of text with computational demands?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.7411\n",
            "   Enhanced System (BGE): 0.8879\n",
            "   Improvement:          +0.1468 (+19.8%)\n",
            "\n",
            "📄 Base Answer: Our proposed method, which dynamically SELF_ROUTE_CONTENT: routes queries based on model self-reflection, ef- fectively combines the strengths of both RAG and LC, achieving comparable performance to L...\n",
            "\n",
            "🚀 Enhanced Answer: In addition to\n",
            "quantitative evaluation, we provide a comprehen-\n",
            "sive analysis comparing RAG and LC, including\n",
            "common failure patterns of RAG, the trade-offs\n",
            "between cost and performance, and the resul...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 12: In terms of chunking methods in Wang's paper, what is the difference in performance between the best and second-best methods in Table 4?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.5864\n",
            "   Enhanced System (BGE): 0.7704\n",
            "   Improvement:          +0.1840 (+31.4%)\n",
            "\n",
            "📄 Base Answer: Noticeably, the performance\n",
            "gap is more significant for the more recent mod-\n",
            "els (GPT-4O and Gemini-1.5-Pro) compared to\n",
            "GPT-3.5-Turbo, highlighting the exceptional long-\n",
            "context understanding capacit...\n",
            "\n",
            "🚀 Enhanced Answer: CHUNKING_STRATEGY: Chunk Sizelyft_2021\n",
            "Average\n",
            "FaithfulnessAverage\n",
            "Relevancy\n",
            "2048 80 .37 91 .11\n",
            "1024 94 .26 95 .56\n",
            "512 97.59 97.41\n",
            "256 97 .22 97.78\n",
            "128 95 .74 97 .22\n",
            "CHUNKING_STRATEGY: Table 3: Compar...\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔍 Query 13: What are the best approaches for the retrieval and reranking modules according to Table 11 in Wang paper?\n",
            "------------------------------------------------------------\n",
            "📊 Similarity Scores:\n",
            "   Base System (MPNet):  0.6309\n",
            "   Enhanced System (BGE): 0.7976\n",
            "   Improvement:          +0.1667 (+26.4%)\n",
            "\n",
            "📄 Base Answer: The query classification module enhances accuracy and reduces latency,\n",
            "while the retrieval and reranking modules significantly improve the systems ability to handle diverse\n",
            "queries.. 5 Discussion\n",
            "5.1 ...\n",
            "\n",
            "🚀 Enhanced Answer: The query classification module enhances accuracy and reduces latency,\n",
            "while the retrieval and reranking modules significantly improve the systems ability to handle diverse\n",
            "queries.. 5 Discussion\n",
            "5.1 ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "📈 OVERALL SUMMARY:\n",
            "============================================================\n",
            "Average Base Score (MPNet):  0.6151\n",
            "Average Enhanced Score (BGE): 0.7996\n",
            "Average Improvement:         +0.1845 (+30.0%)\n",
            "\n",
            "🏆 TOP 3 IMPROVEMENTS:\n",
            "1. Query 1: +83.3% improvement\n",
            "   What is the primary goal of the SELF-ROUTE method proposed by Zhuowan Li?...\n",
            "2. Query 8: +65.8% improvement\n",
            "   Describe the metrics used to evaluate the different embedding models for RAG in ...\n",
            "3. Query 4: +62.7% improvement\n",
            "   What are the trade-offs involved when using different chunking strategies in RAG...\n",
            "\n",
            "💾 Detailed results saved to 'simple_model_comparison.csv'\n"
          ]
        }
      ]
    }
  ]
}